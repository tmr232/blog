<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>More Memory Profiling (in Python) | Tamir Bahar</title><meta name=keywords content><meta name=description content="More lessons learned memory-optimizing Python code."><meta name=author content><link rel=canonical href=https://tamir.dev/posts/more-memory-profiling-in-python/><link crossorigin=anonymous href=/assets/css/stylesheet.f89fe5ba0a1e1e3a66da8210c0add5c0528394d79616f1e033496028ca8dd450.css integrity="sha256-+J/lugoeHjpm2oIQwK3VwFKDlNeWFvHgM0lgKMqN1FA=" rel="preload stylesheet" as=style><link rel=icon href=https://tamir.dev/images/profilepic.jpg><link rel=icon type=image/png sizes=16x16 href=https://tamir.dev/images/profilepic.jpg><link rel=icon type=image/png sizes=32x32 href=https://tamir.dev/images/profilepic.jpg><link rel=apple-touch-icon href=https://tamir.dev/images/profilepic.jpg><link rel=mask-icon href=https://tamir.dev/images/profilepic.jpg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="More Memory Profiling (in Python)"><meta property="og:description" content="More lessons learned memory-optimizing Python code."><meta property="og:type" content="article"><meta property="og:url" content="https://tamir.dev/posts/more-memory-profiling-in-python/"><meta property="og:image" content="https://tamir.dev/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2021-07-02T00:00:00+00:00"><meta property="article:modified_time" content="2021-07-02T00:00:00+00:00"><meta property="og:site_name" content="Tamir Bahar"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://tamir.dev/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="More Memory Profiling (in Python)"><meta name=twitter:description content="More lessons learned memory-optimizing Python code."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://tamir.dev/posts/"},{"@type":"ListItem","position":2,"name":"More Memory Profiling (in Python)","item":"https://tamir.dev/posts/more-memory-profiling-in-python/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"More Memory Profiling (in Python)","name":"More Memory Profiling (in Python)","description":"More lessons learned memory-optimizing Python code.","keywords":[],"articleBody":"TL;DR Graph memory-usage over time, correlate with logs, profit.\nOverconfidence Recently, I had to reduce the memory consumption of a Python process that became entirely unreasonable. Now, a while back I wrote about finding memory leaks in Python. I was pleased with myself and sure that with the knowledge I gained then, I can surely get this done!\nAnd oh, was I wrong…\nHarsh Reality You see, both pympler and tracemalloc are wonderful tools. But like all tools, they have limitations. When you have a long-running (days) process with many (hundreds of millions) objects, the memory and performance costs of your tools add up quite significantly. Waiting for pympler to query all objects takes forever, and following references is completely impractical; viewing tracemalloc statistics is nice, but doesn’t help you narrow things down enough.\nSo, after 2 weeks of zero-to-minimal improvements (though I was sure I’m on the right track) I decided to try a different approach to understanding the memory usage of my code.\nTo The Rescue Enter memlog.py.\nmemlog is a simple, naive tool. It tracks the overall memory usage on a machine, and logs it (with a timestamp) to a CSV. That’s it. While the recorded data may include significant noise, running your code (\u0026 memlog) inside a container can reduce it significantly. Also, background memory noise tends to be insignificant when your process hogging all of your memory…\nSo, I ran my process (with logs), ran memlog, and plotted a memory-over-time graph: And oh, oh no.\nInsight Looking at the graph, we can divide it into 3 parts:\nA near-instant rise at the beginning. This is by far the bulk of the memory-usage increase; A slow, gradual increase over the entire time-scale; A near-instant drop in memory-usage. Those parts are basically:\nLoading the data-set and various initialization; The bulk of the processing; Program termination. And for the past 2 weeks I’ve been busy reducing the memory-usage of… the second part. Being absolutely sure it’s the most significant.\nSo yeah, that hurt. But only for a short time. For you see, with this newfound knowledge I could safely focus on the first few minutes of execution and disregard the rest for the time being.\nTrue. I’ll have to test the whole thing once I’m make any significant changes. Memory-usage might spike at a later point. Memory-optimization may cause performance degradation. But unless I reduce that uptick at the beginning I won’t get any significant improvements.\nProfit A week later, we managed to reduce memory-usage by 30% while reducing overall processing time by a similar percentage. We had to:\nAdd a de-duplicating weakref based cache; Add a pre-processing step; Make our code more cache-friendly by sorting our data; Remove a massively over-engineered control mechanism. But it was all made possible by focusing on the right part. Had I not plotted that memory graph, I could’ve easily spent another 2 weeks without any significant progress.\nOld \u0026 Wise So whatever you do, I highly suggest you graph your data. No need to be smart about it. Log it, graph it, correlate to your logs.\n","wordCount":"515","inLanguage":"en","datePublished":"2021-07-02T00:00:00Z","dateModified":"2021-07-02T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://tamir.dev/posts/more-memory-profiling-in-python/"},"publisher":{"@type":"Organization","name":"Tamir Bahar","logo":{"@type":"ImageObject","url":"https://tamir.dev/images/profilepic.jpg"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://tamir.dev/ accesskey=h title="Tamir Bahar (Alt + H)">Tamir Bahar</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://tamir.dev/posts/ title=posts><span>posts</span></a></li><li><a href=https://tamir.dev/archives/ title=archives><span>archives</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>More Memory Profiling (in Python)</h1><div class=post-description>More lessons learned memory-optimizing Python code.</div><div class=post-meta><span title='2021-07-02 00:00:00 +0000 UTC'>July 2, 2021</span></div></header><div class=post-content><h2 id=tldr>TL;DR<a hidden class=anchor aria-hidden=true href=#tldr>#</a></h2><p>Graph memory-usage over time, correlate with logs, profit.</p><h2 id=overconfidence>Overconfidence<a hidden class=anchor aria-hidden=true href=#overconfidence>#</a></h2><p>Recently, I had to reduce the memory consumption of a Python process that became entirely unreasonable. Now, a while back I wrote about <a href=/posts/finding-a-memory-leak-in-my-python-code>finding memory leaks in Python</a>. I was pleased with myself and sure that with the knowledge I gained then, I can surely get this done!</p><p>And oh, was I wrong&mldr;</p><h2 id=harsh-reality>Harsh Reality<a hidden class=anchor aria-hidden=true href=#harsh-reality>#</a></h2><p>You see, both <a href=https://pympler.readthedocs.io/en/latest/>pympler</a> and <a href=https://docs.python.org/3/library/tracemalloc.html>tracemalloc</a> are wonderful tools. But like all tools, they have limitations. When you have a long-running (days) process with many (hundreds of millions) objects, the memory and performance costs of your tools add up quite significantly. Waiting for <code>pympler</code> to query <em>all objects</em> takes forever, and following references is completely impractical; viewing <code>tracemalloc</code> statistics is nice, but doesn&rsquo;t help you narrow things down enough.</p><p>So, after 2 weeks of zero-to-minimal improvements (though I was <em>sure</em> I&rsquo;m on the right track) I decided to try a different approach to understanding the memory usage of my code.</p><h2 id=to-the-rescue>To The Rescue<a hidden class=anchor aria-hidden=true href=#to-the-rescue>#</a></h2><p>Enter <a href=https://gist.github.com/tmr232/4a10e17ddf4aefcc0c94a15bdddc58f4>memlog.py</a>.</p><p><code>memlog</code> is a simple, naive tool. It tracks the overall memory usage on a machine, and logs it (with a timestamp) to a CSV. That&rsquo;s it. While the recorded data may include significant noise, running your code (& <code>memlog</code>) inside a container can reduce it significantly. Also, background memory noise tends to be insignificant when your process hogging all of your memory&mldr;</p><p>So, I ran my process (with logs), ran <code>memlog</code>, and plotted a memory-over-time graph:
<img loading=lazy src=/images/more-memory-profiling.png alt="The image shows a graph of memory-usage over time. The graph shows a near-instant 4.5-unit rise at the start, then a slow 2-unit rise over a long time, then a near-instant decline back to 0 at the end."></p><p>And oh, oh no.</p><h2 id=insight>Insight<a hidden class=anchor aria-hidden=true href=#insight>#</a></h2><p>Looking at the graph, we can divide it into 3 parts:</p><ol><li>A near-instant rise at the beginning. This is by far the bulk of the memory-usage increase;</li><li>A slow, gradual increase over the entire time-scale;</li><li>A near-instant drop in memory-usage.</li></ol><p>Those parts are basically:</p><ol><li>Loading the data-set and various initialization;</li><li>The bulk of the processing;</li><li>Program termination.</li></ol><p>And for the past 2 weeks I&rsquo;ve been busy reducing the memory-usage of&mldr; the second part. Being absolutely sure it&rsquo;s the most significant.</p><p>So yeah, that hurt. But only for a short time. For you see, with this newfound knowledge I could safely focus on the first few minutes of execution and disregard the rest for the time being.</p><p>True. I&rsquo;ll have to test the whole thing once I&rsquo;m make any significant changes. Memory-usage might spike at a later point. Memory-optimization may cause performance degradation. But unless I reduce that uptick at the beginning I won&rsquo;t get any significant improvements.</p><h2 id=profit>Profit<a hidden class=anchor aria-hidden=true href=#profit>#</a></h2><p>A week later, we managed to reduce memory-usage by 30% while <em>reducing</em> overall processing time by a similar percentage. We had to:</p><ol><li>Add a de-duplicating weakref based cache;</li><li>Add a pre-processing step;</li><li>Make our code more cache-friendly by sorting our data;</li><li>Remove a massively over-engineered control mechanism.</li></ol><p>But it was all made possible by <em>focusing on the right part</em>. Had I not plotted that memory graph, I could&rsquo;ve easily spent another 2 weeks without any significant progress.</p><h1 id=old--wise>Old & Wise<a hidden class=anchor aria-hidden=true href=#old--wise>#</a></h1><p>So whatever you do, I highly suggest you graph your data. No need to be smart about it. Log it, graph it, correlate to your logs.</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2022 <a href=https://tamir.dev/>Tamir Bahar</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>